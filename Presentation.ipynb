{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>Scrapy para usuários de bs4</center>\n",
    "\n",
    "\n",
    "\n",
    "Henrique Coura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## about:me\n",
    "\n",
    "- Engenheiro Mecânico\n",
    "- Programo há 3 anos e meio, 2 anos profissionalmente\n",
    "- Software Engineer na Scrapinghub\n",
    "- Apaixonado por dados: scraping, data processing, machine learning, etc.\n",
    "- https://github.com/hcoura\n",
    "- https://medium.com/@henriquecoura_87435\n",
    "- coura.henrique@gmail.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## bs4 vs scrapy\n",
    "\n",
    "- É como comparar maçãs e laranjas\n",
    "- scrapy é um framework para scraping\n",
    "- Beautiful Soup é um lib para extração de dados de arquivos HTML e XML. Funciona com vários `parsers` e providencia formas idiomáticas de busca, navegação e modificação da árvore de parsing. (Tradução da descrição deles mesmo)\n",
    "- Se quiser, não que eu recomende, pode até usar o bs4 junto com scrapy\n",
    "- bs4 é bom para scripts mais curtos, que só vão rodar algumas vezes\n",
    "- Scrapy é bom para projetos maiores que envolvem maiores complexidades e precisam de uma estrutura mais robusta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## libs semelhantes ao bs4\n",
    "\n",
    "Existem outras libs que você pode utilizar para o mesmo caso de uso do bs4, essas são algumas:\n",
    "\n",
    "- lxml - muito utilizada como base para outras libs, suporta vários parsers(inclusive o do próprio bs4). Encontra elementos via XPATH\n",
    "- parsel - um wrapper para o lxml utilizado pelo scrapy para parsing. Encontra elementos via XPATH e CSS SELECTORS\n",
    "- requests-html - lib novinha que junta um monte de coisa para scraping básico(requests, XPATH, CSS SELECTORS, Mocked user-agent, seguir redirects, persistencia de cookies, renderização de JS, etc.)\n",
    "\n",
    "https://github.com/lxml/lxml\n",
    "\n",
    "https://github.com/kennethreitz/requests-html\n",
    "\n",
    "https://github.com/scrapy/parsel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Comparando bs4 e parsel\n",
    "\n",
    "- Eu não acho a api do bs4 muito intuitiva, ainda mais considerando que é diferente de tudo mais na indústria ao contrário de xpath / css selectors\n",
    "\n",
    "- Por outro lado algumas pessoas devem achar a api do bs4 mais fácil de trabalhar\n",
    "\n",
    "- O parser do bs4 lida um pouco melhor com HTML quebrado mas é mais lento (é possível usar o parser do bs4 no lxml e vice versa)\n",
    "\n",
    "- bs4 não suporta XPATH\n",
    "\n",
    "- parsel usa o lxml e adiciona CSS SELECTORS além de fornecer uma interface um pouco mais fácil de lidar\n",
    "\n",
    "- o scrapy usa o parsel para fazer o parsing por padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from urllib.parse import unquote\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from parsel import Selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>bs4</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "url = 'http://localhost:8000/wikipedia/Clube_Atlético_Mineiro.html'\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'images/120px-Atletico_mineiro_galo.png'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divs = soup.find_all('div', {'class': 'mw-parser-output'})\n",
    "image = None\n",
    "for div in divs:\n",
    "    image = div.find('table').find('img')\n",
    "    if image:\n",
    "        break\n",
    "image['src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clube Atlético Mineiro'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = soup.find(id='firstHeading').text\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Galo.html',\n",
       " '25_de_março.html',\n",
       " '1908.html',\n",
       " 'Estádio_Raimundo_Sampaio.html',\n",
       " 'Mineirão.html']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_links = soup.find('div', id='bodyContent').find_all('a', href=re.compile('^[^:]*\\.html$'))\n",
    "related_links = [unquote(link['href']) for link in related_links]\n",
    "related_links[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O Clube Atlético Mineiro (conhecido apenas por Atlético e cujo acrônimo é CAM) é um clube brasileiro de futebol sediado na cidade de Belo Horizonte, Minas Gerais. Fundado em 25 de março de 1908 por um grupo de estudantes, tem como suas cores tradicionais o preto e o branco. Contudo, o clube teve como primeiro nome Athlético Mineiro Football Club . Seu símbolo e alcunha mais popular é o Galo, mascote oficial no final da década de 1930. O Atlético é um dos clubes mais populares do Brasil.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = divs[0].find('p')\n",
    "paragraph = ''\n",
    "for e in p.children:\n",
    "    try:\n",
    "        if e.find('a', href=re.compile('#cite')):\n",
    "            continue\n",
    "    except:\n",
    "        pass\n",
    "    paragraph += e.string\n",
    "paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center>parsel</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "url = 'http://localhost:8000/wikipedia/Clube_Atlético_Mineiro.html'\n",
    "\n",
    "response = requests.get(url)\n",
    "sel = Selector(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'images/120px-Atletico_mineiro_galo.png'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = sel.css('.mw-parser-output table img::attr(src)').extract_first()\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clube Atlético Mineiro'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = sel.css('#firstHeading::text').extract_first()\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Galo.html',\n",
       " '25_de_março.html',\n",
       " '1908.html',\n",
       " 'Estádio_Raimundo_Sampaio.html',\n",
       " 'Mineirão.html']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_links = sel.xpath('//div[@id=\"bodyContent\"]/descendant::a[re:test(@href, '\n",
    "                          '\"^[^:]*\\.html$\")]/@href').extract()\n",
    "related_links = [unquote(url) for url in related_links]\n",
    "related_links[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O Clube Atlético Mineiro (conhecido apenas por Atlético e cujo acrônimo é CAM) é um clube brasileiro de futebol sediado na cidade de Belo Horizonte, Minas Gerais. Fundado em 25 de março de 1908 por um grupo de estudantes, tem como suas cores tradicionais o preto e o branco. Contudo, o clube teve como primeiro nome  . Seu símbolo e alcunha mais popular é o Galo, mascote oficial no final da década de 1930. O Atlético é um dos clubes mais populares do Brasil.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph = ''.join(sel.xpath('//div[@class=\"mw-parser-output\"]/p[1]/descendant-or-self::*['\n",
    "                                'self::a[not(starts-with(@href, \"#cite\"))] or self::b or self::p]/text()').extract())\n",
    "paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## scrapy\n",
    "\n",
    "**Um framework open source e colaborativo para extração de dados de websites**\n",
    "\n",
    "- Projetos de scraping tendem a ser complexos e cheios de \"erros\" e \"bugs\" que não controlamos\n",
    "- Também são cheios de \"workarounds\" para sites e situações específicas\n",
    "- Mas mesmo assim tem muita coisa \"reaproveitável\" para cada caso\n",
    "- As vezes é preciso \"esquivar\" das defesas do site\n",
    "- O scrapy ajuda em tudo isso e mais um pouco além de fornecer uma estrutura para manter uma base de código mais organizada e mais \"sã\"\n",
    "\n",
    "https://scrapy.org/\n",
    "\n",
    "https://github.com/scrapy/scrapy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Um spider simples\n",
    "\n",
    "Pegando o mesmo exemplo da wikipédia vou mostrar como escrever um crawler que:\n",
    "\n",
    "- Extraia uma página e suas página correlatas na wikipédia;\n",
    "\n",
    "- De cada página extraída teremos: Título, primeiro parágrafo, url da imagem principal, imagem principal(arquivo);\n",
    "\n",
    "- Exportar tudo para um .csv ou .json;\n",
    "\n",
    "- Utilize várias features do scrapy para facilitar nossa vida.\n",
    "\n",
    "\n",
    "```\n",
    "scrapy startproject <project_name> [project_dir]\n",
    "```\n",
    "\n",
    "```\n",
    "scrapy startproject scrapy_project\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Items\n",
    "\n",
    "\n",
    "- O maior objetivo no scraping é transformar dados não-estruturados em estruturados\n",
    "- Os `Items` nos dão estrutura que não temos nos dicts\n",
    "- Não permitem o `assignment` em campos não declarados\n",
    "- Possui uma API similar aos dicts\n",
    "- Vários componentes do scrapy utilizam informações passadas pelos `Items`\n",
    "\n",
    "https://docs.scrapy.org/en/latest/topics/items.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Item Loaders\n",
    "\n",
    "\n",
    "- Fornecem um mecanismo conveniente para popular `Items`\n",
    "- Tornam o processo de limpeza e processamento de dados durante a extração muito mais limpo e fácil de manter e fora do `Spider`\n",
    "\n",
    "https://docs.scrapy.org/en/latest/topics/loaders.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Item Pipelines\n",
    "\n",
    "- Depois que um `Item` é extraído ele é enviado aos `Item Pipelines` que os processam sequencialmente\n",
    "- Cada `Item Pipeline` processam o `Item` executando alguma ação e decidindo se deve ser \"jogado fora\" ou continuar pelo `pipeline`\n",
    "- Alguns casos de uso:\n",
    "    - Limpar dados HTML\n",
    "    - Validação de dados\n",
    "    - Verificação de duplicados\n",
    "    - Armazenar `Items`\n",
    "\n",
    "https://docs.scrapy.org/en/latest/topics/item-pipeline.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exportar para csv / json\n",
    "\n",
    "csv\n",
    "```\n",
    "scrapy crawl [spider name] -o filename.csv\n",
    "```\n",
    "\n",
    "json\n",
    "```\n",
    "scrapy crawl [spider name] -o filename.json\n",
    "```\n",
    "\n",
    "no nosso caso\n",
    "```\n",
    "scrapy crawl wiki -o articles.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Funcionalidades avançadas\n",
    "\n",
    "\n",
    "### Arquitetura\n",
    "\n",
    "![scrapy architecture](scrapy_architecture.png \"Arquitetura do scrapy\")\n",
    "\n",
    "https://docs.scrapy.org/en/latest/topics/architecture.html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "O fluxo de dados é o seguinte:\n",
    "\n",
    "- (1) O `engine` pega as requisições iniciais do `spider`;\n",
    "- (2) Envia as requisições para o `scheduler`;\n",
    "- (3) Recebe as próximas requisições para \"crawlear\";\n",
    "- (4) Enviar as requisições para o `downloader`, passando por todos os `downloader middlewares`;\n",
    "- (5) Depois que o `downloader` termina de baixar a página, ele cria uma resposta e passa ela de volta pelos `downloader middlewares`;\n",
    "- (6) O `engine`, envia as respostas para o `spider` passando pelos `spider middlewares`;\n",
    "- (7) O `spider` processa a resposta e envia para o `engine` itens e requisições;\n",
    "- (8) As requisições enviadas pelo spider vão para o `scheduler` e reinicia o processo, os itens são enviados para os `item pipelines` para o processamento final;\n",
    "- O processo continua até não haver mais requisições no `scheduler`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"hiring.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# <center>Obrigado!</center>\n",
    "\n",
    "\n",
    "\n",
    "### <center>Perguntas?</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Downloader Middleware\n",
    "\n",
    "- O `downloader middleware` é um sistema leve, de mais baixo nível, para conectar ao processo de requisições e resposta do scrapy\n",
    "\n",
    "- Possui dois métodos principais, `process_request(request, spider)` e `process_response(request, response, spider)`\n",
    "\n",
    "- Exemplo built-in: RetryMiddleware que controla quando tentar de novo alguma requisição\n",
    "\n",
    "https://docs.scrapy.org/en/latest/topics/downloader-middleware.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Spider Middleware\n",
    "\n",
    "- O `spider middleware` possui hooks para processar as respostas que são enviadas aos `spiders` e as requisições e items gerados pelos `spiders`\n",
    "\n",
    "- Possui os seguintes métodos principais, `process_spider_input(response, spider)` e `process_spider_output(response, result, spider)`, `process_spider_exception(response, exception, spider)`, `process_start_requests(start_requests, spider)`\n",
    "\n",
    "- Exemplo built-in: DepthMiddleware que controla quão profundo seu spider vai no site\n",
    "\n",
    "https://docs.scrapy.org/en/latest/topics/spider-middleware.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Extensions\n",
    "\n",
    "- Classes normais que são inicializadas no startup do scrapy, geralmente utilizadas para customizações além do que um middleware to oferece\n",
    "\n",
    "https://docs.scrapy.org/en/latest/topics/extensions.html\n",
    "\n",
    "### Signals\n",
    "\n",
    "- O scrapy envia vários \"sinais\" para notificar quando certos eventos ocorrem, você pode pegar esses sinais para adicionar funcionalidades customizadas. Geralmente em uma `extension`, mas podem ser utilizados em outros lugares, como no próprio `spider`\n",
    "\n",
    "https://docs.scrapy.org/en/latest/topics/signals.html"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "livereveal": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
